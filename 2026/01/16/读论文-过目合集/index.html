<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="author" content="lgswdn">
    
    
    
    
    
    
    <title>读论文-过目合集 | lgswdn-SA</title>
    <link href="http://lgswdn.github.io" rel="prefetch" />

    
<link rel="stylesheet" href="/css/bootstrap.min.css">
<link rel="stylesheet" href="/css/aos.css">
<link rel="stylesheet" href="/css/style.css">

    
<script src="/js/jquery.min.js"></script>

    
<script src="/js/bootstrap.min.js"></script>

    
<script src="/js/aos.js"></script>

    
<script src="/js/highslide/highslide-full.min.js"></script>

    
<link rel="stylesheet" href="/js/highslide/highslide.css">

    <style type="text/css">
        @media (max-width: 768px) {
            body {
                background-color: #f0f0f0;
                background: url('/imgs/xsbg.gif');
                background-attachment: fixed;
            }
        }
    </style>
    
    <!--<script type="text/javascript">
      if (document.images) {
        var avatar = new Image();
        avatar.src = '/imgs/logo.png'
        var previews = 'preview1.jpg,preview2.jpg,preview3.jpg,preview4.jpg,preview5.jpg,preview6.jpg,preview7.jpg,preview8.jpg,preview9.jpg,preview10.jpg,preview11.jpg,preview12.jpg'.split(',')
        var previewsPreLoad = []
        for(var i = 0; i < length; i++) {
          previewsPreLoad.push(new Image())
          previewsPreLoad[previewsPreLoad.length - 1].src = '/imgs/preview' + previews[i]
        }
      }
    </script>-->
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"></head>
<body>
    <!-- 背景轮播图功能 -->
    <section class="hidden-xs">
    <ul class="cb-slideshow">
        <li><span>天若</span></li>
        <li><span>有情</span></li>
        <li><span>天亦老</span></li>
        <li><span>我为</span></li>
        <li><span>长者</span></li>
        <li><span>续一秒</span></li>
    </ul>
</section>
    <!-- 欧尼酱功能, 谁用谁知道 -->
    
    <header class="navbar navbar-inverse" id="gal-header">
    <div class="container">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed"
                    data-toggle="collapse" data-target=".bs-navbar-collapse"
                    aria-expanded="false">
                <span class="fa fa-lg fa-reorder"></span>
            </button>
            <a href="http://lgswdn.github.io">
                
                <style>
                    #gal-header .navbar-brand {
                        height: 54px;
                        line-height: 24px;
                        font-size: 28px;
                        opacity: 1;
                        background-color: rgba(0,0,0,0);
                        text-shadow: 0 0 5px #fff,0 0 10px #fff,0 0 15px #fff,0 0 20px #228DFF,0 0 35px #228DFF,0 0 40px #228DFF,0 0 50px #228DFF,0 0 75px #228DFF;
                    }
                </style>
                <!-- 这里使用文字(navbar_text or config.title) -->
                <div class="navbar-brand">lgswdn-SA</div>
                
            </a>
        </div>
        <div class="collapse navbar-collapse bs-navbar-collapse">
            <ul class="nav navbar-nav" id="menu-gal">
                
                
                <li class="">
                    <a href="/">
                        <i class="fa fa-home"></i>首页
                    </a>
                </li>
                
                
                
                <li class="">
                    <a href="/archives">
                        <i class="fa fa-archive"></i>归档
                    </a>
                </li>
                
                
                
                
                <li class="dropdown">
                    <!-- TODO 添加hover dropdown效果 -->
                    <a href="#" class="dropdown-toggle" data-toggle="dropdown"
                       aria-haspopup="true" aria-expanded="false" data-hover="dropdown">
                        <i class="fa fa-list"></i>分类
                    </a>
                    <ul class="dropdown-menu">
                        
                        
                        <li>
                            <a href="/categories/%E9%9A%8F%E8%AE%B0/">随记</a>
                        </li>
                        
                        <li>
                            <a href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">学习笔记</a>
                        </li>
                        
                        <li>
                            <a href="/categories/%E4%B8%AA%E4%BA%BA%E9%9A%8F%E8%AE%B0/">个人随记</a>
                        </li>
                        
                        
                        <li>
                            <a href="/categories">...</a>
                        </li>
                        
                        
                    </ul>
                </li>
                
                
                
                
                
                <li class="dropdown">
                    <!-- TODO 添加hover dropdown效果 -->
                    <a href="#" class="dropdown-toggle" data-toggle="dropdown"
                       aria-haspopup="true" aria-expanded="false" data-hover="dropdown">
                        <i class="fa fa-tags"></i>标签
                    </a>
                    <ul class="dropdown-menu">
                        
                        
                        <li>
                            <a href="/tags/%E6%80%BB%E7%BB%93/">总结</a>
                        </li>
                        
                        <li>
                            <a href="/tags/AI%E5%9F%BA/">AI基</a>
                        </li>
                        
                        <li>
                            <a href="/tags/CVDL/">CVDL</a>
                        </li>
                        
                        
                        <li>
                            <a href="/tags">...</a>
                        </li>
                        
                        
                    </ul>
                </li>
                
                
                
                
                <li class="">
                    <a href="/about">
                        <i class="fa fa-user"></i>关于我
                    </a>
                </li>
                
                
                
                <li class="">
                    <a href="/resources">
                        <i class="fa fa-file"></i>资源
                    </a>
                </li>
                
                
            </ul>
        </div>
    </div>
</header>
    <div id="gal-body">
        <div class="container">
            <div class="row">
                <div class="col-md-8 gal-right" id="mainstay">
                    
<article class="article well article-body" id="article">
    <div class="breadcrumb">
        <i class="fa fa-home"></i>
        <a href="http://lgswdn.github.io">lgswdn-SA</a>
        >
        <span>读论文-过目合集</span>
    </div>
    <!-- 大型设备详细文章 -->
    <div class="hidden-xs">
        <div class="title-article">
            <h1>
                <a href="/2026/01/16/%E8%AF%BB%E8%AE%BA%E6%96%87-%E8%BF%87%E7%9B%AE%E5%90%88%E9%9B%86/">读论文-过目合集</a>
            </h1>
        </div>
        <div class="tag-article">
            
            <span class="label label-gal">
                <i class="fa fa-tags"></i>
                
                <a href="/tags/%E8%AF%BB%E8%AE%BA%E6%96%87/">读论文</a>
                
            </span>
            
            <span class="label label-gal">
                <i class="fa fa-calendar"></i> 2026-01-16
            </span>
            
        </div>
    </div>
    <!-- 小型设备详细文章 -->
    <div class="visible-xs">
        <center>
            <div class="title-article">
                <h4>
                    <a href="/2026/01/16/%E8%AF%BB%E8%AE%BA%E6%96%87-%E8%BF%87%E7%9B%AE%E5%90%88%E9%9B%86/">读论文-过目合集</a>
                </h4>
            </div>
            <p>
                <i class="fa fa-calendar"></i> 2026-01-16
            </p>
            <p>
                
                <i class="fa fa-tags"></i>
                
                <a href="/tags/%E8%AF%BB%E8%AE%BA%E6%96%87/">读论文</a>
                
                
                
            </p>
        </center>
    </div>
    <div class="content-article">
        <h4
id="sim2real-image-translation-enables-viewpoint-robust-policies-from-fixed-camera-datasets">Sim2real
Image Translation Enables Viewpoint Robust Policies from Fixed-Camera
Datasets</h4>
<p>link: https://arxiv.org/pdf/2601.09605</p>
<p>Image translation: we have lots of simulated trajectories, and use
image translation to translate the simulated image to a sim2real
image.</p>
<p>MANGO aims to solve the problems of traditional methods,
including:</p>
<ul>
<li>diffusion is too slow. MANGO uses GAN.</li>
<li>fail to generalize on different viewpoints on the fixed-viewpoints
target domain</li>
</ul>
<p>Methodology: Go through a encoder-decoder model to get a sim2real
translated image with the following losses.</p>
<ul>
<li><p>Use gt segmentation to calculate a segNCE loss, to make sure a
pixel feature is similar to other pixel of the same seg class.</p></li>
<li><p>Encode the result image again to get PatchNCE loss</p></li>
<li><p>GAN loss with fixed-viewpoint real image.</p></li>
</ul>
<p>Result: has rather comparable performance with 35M parameter ACT to
the 4.5B VISTA(another viewpoint augmentation method). However MANGO is
just much faster.</p>
<h4
id="activevla-injecting-active-perception-into-vision-language-action-models-for-precise-3d-robotic-manipulation">ActiveVLA:
Injecting Active Perception into Vision-Language-Action Models for
Precise 3D Robotic Manipulation</h4>
<p>link: https://arxiv.org/pdf/2601.08325</p>
<p>Problem: current VLA models only have static vision perception, which
might fail when occlusion occurs.</p>
<p>ActiveVLA propose a framework that allow us to actively adjust the
camera viewpoint and actively zoom-in to get higher resolution for
critical regions.</p>
<p>Methodology: use a 2-stage strategy.</p>
<ul>
<li><p>First stage (coarse stage), reconstruct point cloud from RGB-D
image, then do orthographic projection before feeding it into a VLM
model (PaliGemma). Then do up-sampling to predict the crucial point and
area for each 2D projection picture, before lifting it to 3D.</p></li>
<li><p>After getting the crucial point in 3D model, select a viewpoint
and zoom-in factor. Feed them into PaliGemma to get image tokens, then
feed it into action encoder to get a final action output.</p>
<p>Viewpoint selection is done consider the 3 criteria: visibility,
camera distance and viewpoint diversity.</p>
<p>Action prediction is done by predicting the grasp position on the 2D
image using an up-sampler. The up-sampler in two stages share weights.
Then we lift it to a 3D transition. For rotation, we discretize each
euler angle into 72 bins and do prediction.</p></li>
</ul>
<p>Evaluation:</p>
<ul>
<li>Achieves a new SOTA on RLBench with 91.8% success rate. Performs
well on precision-demanding tasks, and remain robust under
occlussions.</li>
<li>COLOSSEUM: surpasses BridgeVLA in most category to achieve a new
SOTA. It performs well despite clutter, distractors and viewpoint
changes.</li>
<li>Real-robot: Claims a ~90% success rate on occlusion scenarios.</li>
</ul>
<h4
id="stereovla-enhancing-vision-language-action-models-with-stereo-vision">StereoVLA:
Enhancing Vision-Language-Action Models with Stereo Vision</h4>
<p>link: https://arxiv.org/pdf/2512.21970</p>
<p>Summary: This work proposes a novel Geometric-Semantic feature
Extraction using existed works to extract and fuse semantic feature from
VLM and geometric feature from Foundation Stereo, and enhance higher
precision grasping that need better geometric recognition.</p>
<p>Methodology:</p>
<ul>
<li>For left view, extract picture feature using DINOv2(capturing
details) and SigLIP(capturing high-level sementics) exclusively.</li>
<li>Feed both view into Foundation Stereo. Use the filtered cost value
<span class="math inline">\(V_c&#39;\)</span> in Foundation Stereo model
considering that it provides dense geometric features.</li>
<li>Instead of concatenating them, just stack their channels and do
projection to get geometric-semantic feature.</li>
</ul>
<p>After obtaining the feature, things are similar with pi-0.5.</p>
<p>One thing to mention is that they add a task of "estimating the depth
of pixel (x,y)" inside training. (x,y) are chosen from the object
bounding box.</p>
<p>The work follows GraspVLA and rely heavily on GraspVLA-like synthetic
data along with internet video data, as there is no dataset giving
stereo vision information.</p>
<p>Evaluation: for bar-like object (pencils etc), GraspVLA performs
well. It also reach 80% for medium size object and 30% for small size
object where current SOTA couldn't pick up.</p>
<p>It is worth mentioning that other models often close the gripper too
early, possibly due to the lack of precise spatial perception.</p>
<h4
id="twinaligner-visual-dynamic-alignment-empowers-physics-aware-real2sim2real-for-robotic-manipulation">TwinAligner:
Visual-Dynamic Alignment Empowers Physics-aware Real2Sim2Real for
Robotic Manipulation</h4>
<p>link: https://arxiv.org/pdf/2512.19390</p>
<p>Summery: This work proposes a novel Real2Sim2Real system that
enhances pixel-level visual alignment and dynamic consistency for both
objects and robots by using 3DGS and optimization during the
"Control-Hit-Slide" manner.</p>
<p>Methodology:</p>
<ul>
<li><p>For pixel-level visual alignment, they first build the physical
mesh, then initialize 3D Gaussian center on the vertices, after which
they optimize the 3DGS using color loss and structure loss.</p></li>
<li><p>For articulate objects, build a automated pipeline with 3DOI to
separate the object.</p></li>
<li><p>Dynamic consistency: In the "Control-Hit-Slide" process, the
robot is controlled to move towards the object, then hit the object, and
record the trajectory of the object.</p>
<p>From the process, several dynamics parameters are related: friction,
mass, center of mass, and robot controller parameter.</p>
<p>The work list optimization goals (distance between the sim &amp; real
joint positions vector, and point cloud base object poses ADD &amp;
ADD-S loss), and use gradient-free optimization method (to ensure
compatibility with non-differentiable simulators) to get the
parameters.</p></li>
<li><p>For policy learning, the work simply uses tele-operation in the
simulation environment for data generation, and use imitation learning
policies Diffusion Policy and RISE policy.</p></li>
</ul>
<p>Result: The output result shows a comparable result on a zero-shot
sim2real policy (using only the sim policy) with a real2real policy.</p>
<p>Limitation: Human efforts for data collection still exists as we need
to do the control-hit-slide process, and the accuracy and speed of
dynamic alignment is restricted. Also the model doesn't fit deformable
objects.</p>
<h4
id="on-the-fly-vla-adaptation-via-test-time-reinforcement-learning">On-the-Fly
VLA Adaptation via Test-Time Reinforcement Learning</h4>
<p>link: https://arxiv.org/pdf/2601.06748</p>
<p>Summary: This work proposes a method of Test time RL for VLA (w/o
diffusion) using value-free PPO and dense reward.</p>
<p>Methodology:</p>
<ul>
<li><p>The goal of PPO consists of a clipped policy objective <span
class="math inline">\(clip(r_t(\theta))\hat A_t\)</span>, the value loss
and entropy regularization term. The limited trajectories make it hard
to learn the value, TT-VLA simply discards the value loss and entropy
regularization term, leaving only the clipped policy objective.</p></li>
<li><p>Also, TT-VLA set <span
class="math inline">\(\lambda=\gamma=0\)</span> in GAE, collapsing the
PPO into a one-step formulation.</p></li>
<li><p>About the reward. TT-VLA calculate the "progress" of each time
with the past observations and language instruction using
Vision-Language Action-Critic model (VLAC) (Zhai et al., 2025).</p>
<p>The reward is measured by how much the progress increase /
decrease.</p></li>
</ul>
<p>Limitation: the PPO-based RL framework seems hard to be directly
moved to the diffusion-based policies. However, the dense reward seems a
reasonable option to be considered.</p>
<h4 id="vita-vision-to-action-flow-matching-policy">VITA:
VISION-TO-ACTION FLOW MATCHING POLICY</h4>
<p>link: https://arxiv.org/pdf/2507.13231</p>
<p>Summary: this work proposes a faster flow matching policy that does
not need the cross-attention conditioning and flows directly from latent
visions to latent actions.</p>
<p>Methodology:</p>
<ul>
<li>The basic logic is, use a resnet-18 as vision encoder to encode RGB
into latent space. After which, we flow it to represent a latent action,
and use a auto-encoder to decode the action.</li>
<li>However, there exists several problems:
<ul>
<li>The action space has much lower dimension then the vision
space.</li>
<li>Pre-training AE (auto-encoder) was unreliable to produce a flow
target as the action data is limited and sparse.</li>
<li>Jointly training faces a latent space collapse due to
Training-Inference Gap: the <span class="math inline">\(\hat
z_1\)</span> from encoder and <span class="math inline">\(z_1\)</span>
from ODE solving, are from different distribution.</li>
</ul></li>
<li>These problems are solved by designing an effective learning
framework, where we have the following training objectives:
<ul>
<li>Auto-Encoder loss (<span class="math inline">\(L_1\)</span> loss
between gt action chunk and its reconstruction peer) and Flow-matching
loss (the MSE between gt velocity and its predicted peer)</li>
<li>Flow Latent Decoding (FLD): the MSE between <span
class="math inline">\(D(\hat z_1)\)</span> and gt. and Flow Latent
Consistency (FLC): the MSE between <span
class="math inline">\(z_1\)</span> and <span class="math inline">\(\hat
z_1\)</span>. These two objectives provide equivalent training signals,
though putting them together produces a bit better result.</li>
</ul></li>
</ul>
<p>Note that:</p>
<ul>
<li>This model is only vision-based, and the objective is a
deterministic trajectory rather than a multi-model distribution.</li>
<li>Though the FLD acts as a MSE loss, this loss actually ensures that
the action is precise enough, and optimizes both the decoder and
velocity prediction.</li>
</ul>

    </div>
</article>




  
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
  });
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>
<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/mathjax@2.7.8/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


                </div>
                <aside class="col-md-4 gal-left" id="sidebar">
    <!-- 此为sidebar的搜索框, 非搜索结果页面 -->
<aside id="sidebar-search">
    <div class="search hidden-xs" data-aos="fade-up" data-aos-duration="2000">
        <form class="form-inline clearfix" id="search-form" method="get"
              action="/search/index.html">
            <input type="text" name="s" class="form-control" id="searchInput" placeholder="搜索文章~" autocomplete="off">
            <button class="btn btn-danger btn-gal" type="submit">
                <i class="fa fa-search"></i>
            </button>
        </form>
    </div>
</aside>
    <aside id="sidebar-author">
    <div class="panel panel-gal" data-aos="flip-right" data-aos-duration="3000">
        <div class="panel-heading" style="text-align: center">
            <i class="fa fa-quote-left"></i>
            lgswdn
            <i class="fa fa-quote-right"></i>
        </div>
        <div class="author-panel text-center">
            <img src="/imgs/logo.png" width="140" height="140"
                 alt="个人头像" class="author-image">
            <p class="author-description"></p>
        </div>
    </div>
</aside>
    
    
    

<aside id="sidebar-toc">
    <div class="panel panel-gal recent hidden-xs" data-aos="fade-up" data-aos-duration="2000">
        <div class="panel-heading">
            <i class="fa fa-list-ul"></i>  
            文章目录 
            <i class="fa fa-times-circle panel-remove"></i>
            <i class="fa fa-chevron-circle-up panel-toggle"></i>
        </div>
        
        
        <div class="panel-body toc-container">
            <ol class="toc-list"><li class="toc-list-item toc-list-level-4"><a class="toc-list-link" href="#sim2real-image-translation-enables-viewpoint-robust-policies-from-fixed-camera-datasets"><span class="toc-list-text">Sim2real
Image Translation Enables Viewpoint Robust Policies from Fixed-Camera
Datasets</span></a></li><li class="toc-list-item toc-list-level-4"><a class="toc-list-link" href="#activevla-injecting-active-perception-into-vision-language-action-models-for-precise-3d-robotic-manipulation"><span class="toc-list-text">ActiveVLA:
Injecting Active Perception into Vision-Language-Action Models for
Precise 3D Robotic Manipulation</span></a></li><li class="toc-list-item toc-list-level-4"><a class="toc-list-link" href="#stereovla-enhancing-vision-language-action-models-with-stereo-vision"><span class="toc-list-text">StereoVLA:
Enhancing Vision-Language-Action Models with Stereo Vision</span></a></li><li class="toc-list-item toc-list-level-4"><a class="toc-list-link" href="#twinaligner-visual-dynamic-alignment-empowers-physics-aware-real2sim2real-for-robotic-manipulation"><span class="toc-list-text">TwinAligner:
Visual-Dynamic Alignment Empowers Physics-aware Real2Sim2Real for
Robotic Manipulation</span></a></li><li class="toc-list-item toc-list-level-4"><a class="toc-list-link" href="#on-the-fly-vla-adaptation-via-test-time-reinforcement-learning"><span class="toc-list-text">On-the-Fly
VLA Adaptation via Test-Time Reinforcement Learning</span></a></li><li class="toc-list-item toc-list-level-4"><a class="toc-list-link" href="#vita-vision-to-action-flow-matching-policy"><span class="toc-list-text">VITA:
VISION-TO-ACTION FLOW MATCHING POLICY</span></a></li></ol>
        </div>
    </div>
</aside>

    
    
    <!-- 要配置好leancloud才能开启此小工具 -->
    
    
    
    
    <aside id="gal-sets">
        <div class="panel panel-gal hidden-xs" data-aos="fade-up" data-aos-duration="2000">
            <ul class="nav nav-pills pills-gal">

                
                <li>
                    <a href="/2026/01/16/%E8%AF%BB%E8%AE%BA%E6%96%87-%E8%BF%87%E7%9B%AE%E5%90%88%E9%9B%86/index.html#sidebar-tags" data-toggle="tab" id="tags-tab">热门标签</a>
                </li>
                
                
                
                <li>
                    <a href="/2026/01/16/%E8%AF%BB%E8%AE%BA%E6%96%87-%E8%BF%87%E7%9B%AE%E5%90%88%E9%9B%86/index.html#sidebar-links" data-toggle="tab" id="links-tab">个人链接</a>
                </li>
                
            </ul>
            <div class="tab-content">
                
                <div class="cloud-tags tab-pane nav bs-sidenav fade" id="sidebar-tags">
    
    <a href="/tags/%E6%80%BB%E7%BB%93/" style="font-size: 12.786364071382422px;" class="tag-cloud-link">总结</a>
    
    <a href="/tags/AI%E5%9F%BA/" style="font-size: 13.51286068756464px;" class="tag-cloud-link">AI基</a>
    
    <a href="/tags/CVDL/" style="font-size: 10.867248795943873px;" class="tag-cloud-link">CVDL</a>
    
    <a href="/tags/ICS/" style="font-size: 11.37083443636862px;" class="tag-cloud-link">ICS</a>
    
    <a href="/tags/%E5%85%B7%E8%BA%AB/" style="font-size: 16.35686032766301px;" class="tag-cloud-link">具身</a>
    
    <a href="/tags/%E5%88%9D%E6%81%8B%E6%97%A5%E8%AE%B0/" style="font-size: 19.377598802118836px;" class="tag-cloud-link">初恋日记</a>
    
    <a href="/tags/%E8%85%BE%E8%AE%AF%E6%98%9F%E7%81%AB%E8%90%A5/" style="font-size: 8.246610554350978px;" class="tag-cloud-link">腾讯星火营</a>
    
    <a href="/tags/%E6%95%B0%E5%88%86/" style="font-size: 11.88663765637388px;" class="tag-cloud-link">数分</a>
    
    <a href="/tags/%E7%A8%8B%E8%AE%BE/" style="font-size: 11.08418000334099px;" class="tag-cloud-link">程设</a>
    
    <a href="/tags/%E4%B8%AD%E5%9B%BD%E7%9A%84%E4%BA%9A%E6%B4%B2%E5%86%85%E9%99%86%E8%BE%B9%E7%96%86/" style="font-size: 12.861532385984734px;" class="tag-cloud-link">中国的亚洲内陆边疆</a>
    
    <a href="/tags/%E6%B3%A2%E4%BC%8F%E5%A8%83/" style="font-size: 16.521437516720603px;" class="tag-cloud-link">波伏娃</a>
    
    <a href="/tags/%E9%9F%B3%E6%95%B0/" style="font-size: 18.997865517931643px;" class="tag-cloud-link">音数</a>
    
    <a href="/tags/%E9%AB%98%E4%BB%A3/" style="font-size: 19.730114907506522px;" class="tag-cloud-link">高代</a>
    
    <a href="/tags/%E4%BF%A1%E6%A6%82%E7%BB%9F/" style="font-size: 15.339308568468109px;" class="tag-cloud-link">信概统</a>
    
    <a href="/tags/%E6%95%B0%E7%AE%97/" style="font-size: 19.267058262282436px;" class="tag-cloud-link">数算</a>
    
    <a href="/tags/%E7%A6%BB%E6%95%A3/" style="font-size: 10.138185866108323px;" class="tag-cloud-link">离散</a>
    
    <a href="/tags/%E6%99%BA%E9%9A%9C%E9%9B%86%E9%94%A6/" style="font-size: 8.15804987375773px;" class="tag-cloud-link">智障集锦</a>
    
    <a href="/tags/%E8%AF%BB%E8%AE%BA%E6%96%87/" style="font-size: 12.463800113477195px;" class="tag-cloud-link">读论文</a>
    
    <a href="/tags/bandit/" style="font-size: 13.690414635465503px;" class="tag-cloud-link">bandit</a>
    
</div>
                
                
                
                <div class="links tab-pane nav bs-sidenav fade" id="sidebar-links">
    
    <li>
        <a href="https://github.com/lgswdn" target="_blank">Github</a>
    </li>
    
    <li>
        <a href="https://x.com/lgswdn_ChrisZ" target="_blank">X (Twitter)</a>
    </li>
    
    <li>
        <a href="https://www.luogu.com.cn/user/180652" target="_blank">洛谷</a>
    </li>
    
</div>
                
            </div>
        </div>
    </aside>
    
</aside>
            </div>
        </div>
    </div>
    <footer id="gal-footer">
    <div class="container">
        Copyright © 2018 lgswdn Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>.&nbsp;Theme by <a href="https://github.com/ZEROKISEKI" target="_blank">AONOSORA</a>
    </div>
</footer>

<!-- 回到顶端 -->
<div id="gal-gotop">
    <i class="fa fa-angle-up"></i>
</div>
</body>

<script src="/js/activate-power-mode.js"></script>

<script>

    // 配置highslide
	hs.graphicsDir = '/js/highslide/graphics/'
    hs.outlineType = "rounded-white";
    hs.dimmingOpacity = 0.8;
    hs.outlineWhileAnimating = true;
    hs.showCredits = false;
    hs.captionEval = "this.thumb.alt";
    hs.numberPosition = "caption";
    hs.align = "center";
    hs.transitions = ["expand", "crossfade"];
    hs.lang.number = '共%2张图, 当前是第%1张';
    hs.addSlideshow({
      interval: 5000,
      repeat: true,
      useControls: true,
      fixedControls: "fit",
      overlayOptions: {
        opacity: 0.75,
        position: "bottom center",
        hideOnMouseOut: true
      }
    })

    // 初始化aos
    AOS.init({
      duration: 1000,
      delay: 0,
      easing: 'ease-out-back'
    });

</script>
<script>
	POWERMODE.colorful = 'true';    // make power mode colorful
	POWERMODE.shake = 'true';       // turn off shake
	// TODO 这里根据具体情况修改
	document.body.addEventListener('input', POWERMODE);
</script>
<script>
    window.slideConfig = {
      prefix: '/imgs/slide/background',
      ext: 'jpg',
      maxCount: '6'
    }
</script>

<script src="/js/hs.js"></script>
<script src="/js/blog.js"></script>




</html>